---
title: "Deploy MPLOPS 2"
emoji: "ğŸš€"
colorFrom: "blue"
colorTo: "green"
sdk: "docker"
sdk_version: "latest"
app_file: "app.py"
pinned: false
---

ğŸ“– PrÃ©sentation du projet

Cette API fournit un service dâ€™infÃ©rence permettant dâ€™Ã©valuer la solvabilitÃ© dâ€™un client dans le cadre dâ€™une demande de prÃªt.
Elle sâ€™intÃ¨gre dans un pipeline MLOps complet incluant versioning des modÃ¨les, monitoring, conteneurisation et automatisation CI/CD.

ğŸ§­ FonctionnalitÃ©s principales

ğŸ“Š Lister les modÃ¨les ML disponibles (/models)

ğŸ¤– PrÃ©dire la solvabilitÃ© dâ€™un client (/predict)

ğŸ—„ï¸ Enregistrer automatiquement les donnÃ©es dâ€™entrÃ©e et de sortie en base

ğŸ“š Documentation OpenAPI/Swagger gÃ©nÃ©rÃ©e automatiquement

ğŸ³ DÃ©ploiement Docker-Ready

---

## ğŸ“¦ PrÃ©requis

- Python 3.12+
- [Poetry](gestion des dÃ©pendances)
- Docker (PostgreSQL local via Compose)

---

## Installation

### 1. Cloner le dÃ©pÃ´t
~~~bash
git https://github.com/marintosti12/MLOPS2-banque.git
cd MLOPS2-banque
~~~


### 2. CrÃ©er un environnement virtuel avec Poetry
~~~bash
poetry install
~~~

### 3. Configurer lâ€™environnement

CrÃ©e un fichier **.env** Ã  la racine :

~~~env
# PostgreSQL
DATABASE_URL=postgresql+psycopg2://futu:futu_pass@localhost:5432/futurisys
# Hugging Face
HF_TOKEN= Token Hugging Face
HF_REPO_ID= Repo Hugging Face
~~~


### 4. Base de donnÃ©es / Grafana

~~~bash
sudo docker compose up -d
~~~

ğŸ—„ï¸ Base de donnÃ©es

~~~mermaid
classDiagram
    direction LR

    class MLModel {
        +UUID id
        +String name
        +Text description
        +DateTime created_at
        +Boolean is_active
    }

    class MLInput {
        +UUID id
        +DateTime created_at
        +String model_name
        +JSONB raw_data
        +JSONB features
    }

    class MLOutput {
        +UUID id
        +UUID input_id
        +String request_id
        +String model_name
        +String model_version
        +DateTime created_at
        +Integer latency_ms
        +String prediction
        +Float prob
        +Float proba_defaut
        +Float proba_solvable
        +Float threshold
        +JSONB classes
        +JSONB meta
        +String error
    }

    class ProfilingLog {
        +UUID id
        +DateTime created_at
        +String endpoint
        +String method
        +String model_name
        +Float total_time_ms
        +Integer num_predictions
        +Float time_preprocessing_ms
        +Float time_inference_ms
        +Float time_database_ms
        +Float time_serialization_ms
        +JSON top_functions
        +Integer ncalls_total
        +Integer ncalls_pandas
        +Integer ncalls_database
        +Float cpu_percent
        +Float memory_mb
        +Text full_profile
    }

    %% Relations
    MLInput "1" --> "0..*" MLOutput : input_id
~~~

### 5. Lancer Migrations

~~~bash
poetry run alembic upgrade head
~~~

### 7. Lancer lâ€™API

~~~bash
poetry run uvicorn src.main:app --reload 
~~~

### 8. Huggings Face

Pour gÃ©nÃ©rer les artefacts, exÃ©cuter les notebooks de machine learning.

Sur Hugging Face (Models), stocker les artefacts du modÃ¨le dans le dÃ©pÃ´t du Space (models/) et nommer le fichier exactement comme le nom du modÃ¨le en base de donnÃ©es.


### ğŸ§¹ QualitÃ© de code

**Lint :**
~~~bash
poetry run ruff check .
~~~

### ğŸ§ª Tests & Couverture

**Lancer les tests :**
```bash
poetry run pytest --maxfail=1 --disable-warnings -q
